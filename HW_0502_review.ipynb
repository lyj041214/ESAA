{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpstbIKY7I2PV35YM/P4Nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyj041214/ESAA/blob/main/HW_0502_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터\n",
        "Otto Group Product Classification Challenge는 상품의 속성을 보고 어떤 카테고리인지 예측하는 문제이다.\n",
        "해당 대회에서 제공된 데이터셋은 93개의 feature와 200,000개 이상의 상품 데이터를 포함하고 있다. 목표는 주요 제품 카테고리들을 구별할 수 있는 예측 모델을 구축하는 것이다.\n",
        "\n",
        "# 코드 흐름\n",
        "스태킹+feature engineering+모델 앙상블 결합\n",
        "1.\n",
        "- 33개의 서로 다른 모델 학습\n",
        "- 모두 5-fold-cross-validation index로 학습\n",
        "- 데이터 전처리 방식: 로그 변환, 스케일링, 루트 변환 등\n",
        "2.\n",
        "- 1단계의 33개 메타 특성 + 1단계에서 생성된 7개의 특성을 입력\n",
        "- 3개의 모델 학습, 각 4-fold-cross-validation\n",
        "- 교차검증 결과를 통해 성능 추정 및 무의미한 모델 제거\n",
        "3.\n",
        "- 2단계 3개 모델의 예측값 결합\n",
        "- XGBoost에 비중을 많이 두고 NN과 ExtraTrees 예측도 함께 반영\n",
        "\n",
        "# 차별점, 배울점\n",
        "-\t수작업으로 만든 8개의 engineered features를 포함하였다는 것이 인상적이었다.\n",
        "-\t교차검증 결과를 통해 무의미한 모델을 제거하는 과정도 적절한 타이밍에 필요하다는 것을 느꼈다.\n",
        "-\t여러 모델의 예측값을 결합하는 과정에서 특정 모델에 가중치를 두어 정확도를 높이는 과정이 중요하다고 느꼈다.\n"
      ],
      "metadata": {
        "id": "8EuOFbizaLCl"
      }
    }
  ]
}